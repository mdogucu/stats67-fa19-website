---
output: 
  pdf_document:
    template: template.tex
---


\large$\bar{x} = \frac{\Sigma_{i=1}^nx_i}{n}$ \hspace{4cm} $s^2 = \frac{\Sigma_{i=1}^n(x_i-\bar{x})}{n-1}$

$P(A^c) = 1 - P(A)$ \hspace{3cm} $P(A \cup B) = P(A) + P(B) - P(A\cap B)$

\large$P(A|B) = \frac{P(A \cap B)}{P(B)} = \frac{P(B|A)P(A)}{P(B|A)P(A) + P(B|A^c)P(A^c)}$

\section*{Discrete Random Variables}

Let $X$ be a discrete random variable with a pmf of $p(x)$ then

$E[X] = \displaystyle \sum_{x} x p(x)$  

Let $X$ be a random variable, then

$Var(X) = E[X^2] - E[X]^2$

Linear combination of random variables $X$ and $Y$ and fixed numbers $a$ and $b$:  

$E[aX+bY] = aE[X] + bE[Y]$  
$Var(aX+bY) = a^2Var(X)+b^2Var(Y)$


\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Distribution} & \textbf{pmf} & \textbf{$E(X)$} & \textbf{$Var(X)$} \\ \hline
Binomial        & \large${n \choose k} p^k (1-p)^{n-k}$            & \large$np$ & \large$np(1-p)$                 \\ \hline
Geometric           & \large$(1-p)^{n-1}p$ & \large$\frac{1}{p}$ & \large$\frac{1-p}{p^2}$                 \\ \hline
Discrete Uniform           & \large$\frac{1}{n}$ & \large$\frac{a+b}{2}$ & \large$\frac{(b-a+1)^2-1}{12}$                 \\ \hline
Poisson          & \large$\frac{\lambda^k}{k!}e^{-\lambda}$ & \large$\lambda$ & \large$\lambda$                 \\ \hline
\end{tabular}
\end{table}


\section*{Continuous Random Variables}

$E[X] =  \int_{x \in \Omega_x} x f(x) \,dx$

\begin{table}[H]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Distribution} & \textbf{pmf} & \textbf{$E(X)$} & \textbf{$Var(X)$} \\ \hline
Continous Uniform        & \large$\frac{1}{b-a}$            & \large$\frac{a+b}{2}$ & \large$\frac{(b-a)^2}{12}$                 \\ \hline
Exponential           & \large$\lambda e^{-\lambda x}$ & \large$\frac{1}{\lambda}$ & \large$\frac{1}{\lambda^2}$                 \\ \hline
Normal           & \large$\frac{1}{\sqrt{2\pi\sigma^2}} e ^{-\frac{(x-\mu)^2}{2\sigma^2}}$ & \large$\mu$ & \large$\sigma^2$                 \\ \hline

\end{tabular}
\end{table}


\newpage

\section*{Central Limit Theorem}

Under certain conditions:

$\bar x \sim N(\mu, \frac{\sigma^2}{n})$

$(\bar x_1 - \bar x_2) \sim N(\mu_1 - \mu_2, \frac{\sigma_1^2}{n_1}+ \frac{\sigma_2^2}{n_2})$  

$\hat p \sim N(p, \frac{p(1-p)}{n})$

$(\hat p_1 - \hat p_2) \sim N((p_1 - p_2), \frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2})$


Also note that

$\hat p_{pooled} = \frac{\hat p_1 n_1 + \hat p_2 n_2}{n_1 + n_2}$

\section*{Linear Regression}

$y = \beta_0 + \beta_1x_1 + \beta_2x_2 +....+\beta_kx_k+ \epsilon$

$b_1 = \large\frac{s_y}{s_x}R$  
$b_0 = \large\bar{y} - b_1\bar x$

\section*{Maximum Likelihood}

The likelihood function 

$L(\bar \theta) = f_1(x_1, \bar \theta)\times....f_n(x_n, \bar \theta)$

MLE estimator of $\bar \theta$ is

$\hat {\bar \theta}=\arg\!\max_{\bar\theta} L(\bar\theta) = \arg\!\max_{\bar\theta}ln L(\bar\theta)$



